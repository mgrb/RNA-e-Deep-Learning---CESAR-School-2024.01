{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sulShD5y4K7V"
      },
      "source": [
        "# Treinamento com interface de alto nível"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mALEfpx54K7d"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aOn4IXXnGRBg"
      },
      "outputs": [],
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WN69WSbu4K7f"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from PIL import UnidentifiedImageError\n",
        "from torch.utils.data import Dataset, random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "BzAXEgxguXre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "!curl -L -o /content/archive.zip https://www.kaggle.com/api/v1/datasets/download/shaunthesheep/microsoft-catsvsdogs-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BPx0q8UubA4",
        "outputId": "13e22e1e-28b4-41d5-c3f2-83fc0253dc2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  787M  100  787M    0     0  20.9M      0  0:00:37  0:00:37 --:--:-- 22.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q -o /content/archive.zip -d /content/cats-dogs"
      ],
      "metadata": {
        "id": "wpAmUcK4uwiR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cats_dogs_folder = \"/content/cats-dogs/PetImages\""
      ],
      "metadata": {
        "id": "YX6UwQi1vAE2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([\n",
        "    transforms.Resize((100,100)),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    ])"
      ],
      "metadata": {
        "id": "5Cez06ZGvSy6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(datasets.ImageFolder):\n",
        "  def __getitem__(self, index):\n",
        "    try:\n",
        "      return super(CustomDataset, self).__getitem__(index)\n",
        "    except UnidentifiedImageError:\n",
        "      print(f\"Skipped problematic image {index}\")\n",
        "      return None"
      ],
      "metadata": {
        "id": "fORDyj5Uvowm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(cats_dogs_folder, transform)"
      ],
      "metadata": {
        "id": "R11Zs1qZxfvF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train, dataset_test = random_split(dataset, [0.7, 0.3])"
      ],
      "metadata": {
        "id": "hTbh0IkFyIDM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOgzedZ_yZfG",
        "outputId": "006b2b4b-caa5-435c-e2dc-c8c570a28647"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17500"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_5ej-ZcybLF",
        "outputId": "bd400102-0e16-4a8c-d714-633d7be37941"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7500"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "pp1z8PqOymws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "  batch = list(filter(lambda x: x is not None, batch))\n",
        "  return torch.utils.data.default_collate(batch)"
      ],
      "metadata": {
        "id": "dAq1qqAIy0dT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(1111)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': 500}\n",
        "test_kwargs = {'batch_size': 100}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train,**train_kwargs, collate_fn=custom_collate_fn)\n",
        "test_loader = torch.utils.data.DataLoader(dataset_test, **test_kwargs, collate_fn=custom_collate_fn)"
      ],
      "metadata": {
        "id": "mau9VWL2ypFz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T8iS1Jc4K7q"
      },
      "source": [
        "## Criação da rede"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RUi00oew4K7q"
      },
      "outputs": [],
      "source": [
        "input_size = 100*100\n",
        "output_size = 2\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_size, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 8192),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8192, 8192),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8192, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, input_size)\n",
        "        x = self.fc(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "model = Net()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-HsB4r6mXdR",
        "outputId": "90bba293-03c8-44fa-b2e2-a15853439d69"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=10000, out_features=2048, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=4096, out_features=8192, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=8192, out_features=8192, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=8192, out_features=4096, bias=True)\n",
              "    (9): ReLU()\n",
              "    (10): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "    (11): ReLU()\n",
              "    (12): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (13): ReLU()\n",
              "    (14): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (15): ReLU()\n",
              "    (16): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (17): ReLU()\n",
              "    (18): Linear(in_features=256, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "TRjwMbTd0JOC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "400Lbat24K7v"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(dataset_train[5][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqLnH5gE0K9J",
        "outputId": "b3127912-bf04-4542-9ca3-11aa572298bc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6807, -0.7058]], grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cqllMDO4K7y"
      },
      "source": [
        "### Criando o objeto de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "OAEOQoZy4K72"
      },
      "outputs": [],
      "source": [
        "def train(log_interval, dry_run, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            if dry_run:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eE6DjiKK4K76"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    acc = 100. * correct / len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        acc))\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxdm4FTK4K8E"
      },
      "source": [
        "## Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kgH7e25qb_-K",
        "outputId": "91c909da-2123-4330-c4a3-8dd50b303491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6932, Accuracy: 3770/7500 (50%)\n",
            "\n",
            "Train Epoch: 1 [0/17500 (0%)]\tLoss: 0.693253\n",
            "Skipped problematic image 8790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [5000/17500 (29%)]\tLoss: 0.693731\n",
            "Skipped problematic image 14395\n",
            "Train Epoch: 1 [10000/17500 (57%)]\tLoss: 0.689854\n",
            "Train Epoch: 1 [15000/17500 (86%)]\tLoss: 0.691854\n",
            "\n",
            "Test set: Average loss: 0.6805, Accuracy: 4078/7500 (54%)\n",
            "\n",
            "Train Epoch: 2 [0/17500 (0%)]\tLoss: 0.671882\n",
            "Train Epoch: 2 [5000/17500 (29%)]\tLoss: 0.688344\n",
            "Skipped problematic image 14395\n",
            "Train Epoch: 2 [10000/17500 (57%)]\tLoss: 0.685100\n",
            "Skipped problematic image 8790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 [15000/17500 (86%)]\tLoss: 0.668594\n",
            "\n",
            "Test set: Average loss: 0.6657, Accuracy: 4491/7500 (60%)\n",
            "\n",
            "Train Epoch: 3 [0/17500 (0%)]\tLoss: 0.658664\n",
            "Train Epoch: 3 [5000/17500 (29%)]\tLoss: 0.642683\n",
            "Skipped problematic image 14395\n",
            "Train Epoch: 3 [10000/17500 (57%)]\tLoss: 0.671057\n",
            "Skipped problematic image 8790\n",
            "Train Epoch: 3 [15000/17500 (86%)]\tLoss: 0.662643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6632, Accuracy: 4488/7500 (60%)\n",
            "\n",
            "Train Epoch: 4 [0/17500 (0%)]\tLoss: 0.651264\n",
            "Skipped problematic image 14395\n",
            "Train Epoch: 4 [5000/17500 (29%)]\tLoss: 0.645732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 4 [10000/17500 (57%)]\tLoss: 0.677633\n",
            "Train Epoch: 4 [15000/17500 (86%)]\tLoss: 0.655622\n",
            "Skipped problematic image 8790\n",
            "\n",
            "Test set: Average loss: 0.6554, Accuracy: 4544/7500 (61%)\n",
            "\n",
            "Train Epoch: 5 [0/17500 (0%)]\tLoss: 0.647871\n",
            "Train Epoch: 5 [5000/17500 (29%)]\tLoss: 0.604591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped problematic image 14395\n",
            "Train Epoch: 5 [10000/17500 (57%)]\tLoss: 0.622535\n",
            "Skipped problematic image 8790\n",
            "Train Epoch: 5 [15000/17500 (86%)]\tLoss: 0.589838\n",
            "\n",
            "Test set: Average loss: 0.6479, Accuracy: 4618/7500 (62%)\n",
            "\n",
            "Train Epoch: 6 [0/17500 (0%)]\tLoss: 0.603389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 6 [5000/17500 (29%)]\tLoss: 0.575954\n",
            "Skipped problematic image 14395\n",
            "Train Epoch: 6 [10000/17500 (57%)]\tLoss: 0.571234\n",
            "Skipped problematic image 8790\n",
            "Train Epoch: 6 [15000/17500 (86%)]\tLoss: 0.588991\n",
            "\n",
            "Test set: Average loss: 0.6786, Accuracy: 4564/7500 (61%)\n",
            "\n",
            "Train Epoch: 7 [0/17500 (0%)]\tLoss: 0.587328\n",
            "Skipped problematic image 8790\n",
            "Train Epoch: 7 [5000/17500 (29%)]\tLoss: 0.553419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped problematic image 14395\n",
            "Train Epoch: 7 [10000/17500 (57%)]\tLoss: 0.598868\n",
            "Train Epoch: 7 [15000/17500 (86%)]\tLoss: 0.561668\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-11eb78646595>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"catsdogs_nn.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-f45773240aa0>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 8\n",
        "scheduler = StepLR(optimizer, step_size=4, gamma=0.7)\n",
        "best_acc = test(model, device, test_loader)\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(10, False, model, device, train_loader, optimizer, epoch)\n",
        "    acc = test(model, device, test_loader)\n",
        "    if acc > best_acc:\n",
        "      torch.save(model.state_dict(), \"catsdogs_nn.pt\")\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0uDI8WZtrmgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aux = torch.load(\"mnist_cnn.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kKUxLuJpDB9",
        "outputId": "73c5dc7c-3fd4-46da-a535-478769904c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-cb91ad9ab067>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  aux = torch.load(\"mnist_cnn.pt\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aux"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gpjoGcjpJyn",
        "outputId": "e81058b1-75c7-4991-de62-72a950b6a4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer1.weight',\n",
              "              tensor([[-0.0003, -0.0271,  0.0240,  ...,  0.0353,  0.0151, -0.0153],\n",
              "                      [-0.0208, -0.0123,  0.0298,  ...,  0.0074, -0.0148, -0.0048],\n",
              "                      [ 0.0010, -0.0267, -0.0105,  ...,  0.0171,  0.0191,  0.0073],\n",
              "                      ...,\n",
              "                      [-0.0194,  0.0303,  0.0269,  ...,  0.0003,  0.0118, -0.0055],\n",
              "                      [ 0.0055, -0.0117, -0.0062,  ..., -0.0226, -0.0015, -0.0182],\n",
              "                      [ 0.0190, -0.0259, -0.0127,  ..., -0.0030,  0.0031, -0.0264]],\n",
              "                     device='cuda:0')),\n",
              "             ('layer1.bias',\n",
              "              tensor([-0.0177, -0.0261, -0.0074,  ..., -0.0339, -0.0301,  0.0227],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.weight',\n",
              "              tensor([[-0.0271, -0.0070, -0.0012,  ..., -0.0216,  0.0065, -0.0299],\n",
              "                      [-0.0017,  0.0243,  0.0073,  ...,  0.0054, -0.0276,  0.0368],\n",
              "                      [-0.0211, -0.0065,  0.0098,  ..., -0.0161, -0.0151, -0.0032],\n",
              "                      ...,\n",
              "                      [ 0.0059,  0.0126, -0.0055,  ..., -0.0082, -0.0226, -0.0052],\n",
              "                      [ 0.0257,  0.0050, -0.0087,  ...,  0.0275, -0.0055, -0.0351],\n",
              "                      [-0.0215,  0.0005,  0.0069,  ..., -0.0098, -0.0148,  0.0065]],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.bias',\n",
              "              tensor([ 0.0080, -0.0085,  0.0200,  ..., -0.0200, -0.0203,  0.0019],\n",
              "                     device='cuda:0')),\n",
              "             ('layer3.weight',\n",
              "              tensor([[ 8.6002e-03, -1.5242e-02,  1.5303e-02,  ..., -3.1792e-03,\n",
              "                        3.2702e-03,  8.2730e-03],\n",
              "                      [-1.3425e-02, -9.5412e-03,  9.1319e-05,  ...,  6.6351e-03,\n",
              "                        8.1697e-03, -4.1655e-03],\n",
              "                      [-1.5025e-02, -1.9358e-03,  7.1411e-03,  ..., -9.2033e-03,\n",
              "                       -7.6414e-03, -9.8500e-03],\n",
              "                      ...,\n",
              "                      [-1.9529e-02, -3.3926e-03, -7.8160e-03,  ...,  4.6348e-03,\n",
              "                        8.2284e-03,  5.7517e-04],\n",
              "                      [ 8.6560e-03, -1.5831e-02, -1.4455e-02,  ...,  1.1937e-02,\n",
              "                        6.5405e-03,  1.5512e-03],\n",
              "                      [ 9.1479e-03,  6.1673e-03, -1.0887e-02,  ...,  7.4635e-03,\n",
              "                        9.9701e-03,  8.5691e-03]], device='cuda:0')),\n",
              "             ('layer3.bias',\n",
              "              tensor([-0.0132,  0.0181,  0.0207,  ...,  0.0236,  0.0158,  0.0053],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.weight',\n",
              "              tensor([[-0.0126,  0.0038, -0.0177,  ..., -0.0020, -0.0274,  0.0033],\n",
              "                      [-0.0223, -0.0089, -0.0147,  ..., -0.0015, -0.0042, -0.0208],\n",
              "                      [ 0.0004,  0.0173,  0.0612,  ..., -0.0349,  0.0305, -0.0034],\n",
              "                      ...,\n",
              "                      [-0.0161,  0.0053, -0.0058,  ..., -0.0038,  0.0289, -0.0130],\n",
              "                      [-0.0115, -0.0200,  0.0078,  ...,  0.0045,  0.0145,  0.0183],\n",
              "                      [-0.0112,  0.0017, -0.0201,  ...,  0.0091, -0.0254,  0.0230]],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.bias',\n",
              "              tensor([ 0.0269, -0.0258,  0.0659, -0.0123,  0.1504, -0.0026,  0.1080, -0.0042,\n",
              "                       0.1430,  0.1138,  0.1267,  0.2738,  0.1251,  0.0132, -0.0581,  0.1312,\n",
              "                       0.0095,  0.0983,  0.1366,  0.1701,  0.1165,  0.0763,  0.0109, -0.0047,\n",
              "                       0.0929, -0.0106, -0.0215,  0.0317, -0.0254,  0.0012, -0.0103, -0.0224,\n",
              "                       0.0066,  0.1362, -0.0151, -0.0313, -0.0366, -0.0018,  0.1874,  0.0425,\n",
              "                      -0.0015,  0.0083,  0.1001,  0.0704, -0.0329,  0.1404,  0.1502,  0.2278,\n",
              "                       0.1893, -0.0131,  0.2378,  0.0240,  0.0891, -0.0013,  0.0077, -0.0267,\n",
              "                      -0.0127,  0.2062, -0.0357,  0.1723,  0.0595,  0.1425, -0.0246,  0.0337,\n",
              "                       0.0038,  0.1862,  0.2007,  0.0747, -0.0125,  0.2154,  0.1491, -0.0211,\n",
              "                      -0.0241, -0.0009, -0.0036,  0.1327,  0.2094,  0.1951,  0.1505, -0.0079,\n",
              "                       0.0504,  0.1172,  0.0240, -0.0202,  0.0995,  0.0642, -0.0222, -0.0127,\n",
              "                       0.1139,  0.1535,  0.0626, -0.0082,  0.0842,  0.0720,  0.1942,  0.0444,\n",
              "                       0.0308,  0.1200,  0.0032,  0.0955,  0.1672, -0.0329, -0.0055,  0.0464,\n",
              "                       0.1457, -0.0387,  0.0500,  0.0541,  0.1714,  0.0661,  0.2215,  0.1953,\n",
              "                       0.0523,  0.2368,  0.0762,  0.0289, -0.0033,  0.1604,  0.0946,  0.0893,\n",
              "                       0.0167,  0.1994,  0.1080,  0.2178,  0.0427,  0.1618,  0.2085,  0.0891],\n",
              "                     device='cuda:0')),\n",
              "             ('fc2.weight',\n",
              "              tensor([[-0.2308, -0.0135, -0.1465,  ..., -0.3545, -0.3925,  0.0566],\n",
              "                      [-0.0956, -0.0715,  0.1991,  ...,  0.0321, -0.0112,  0.0318],\n",
              "                      [ 0.0611, -0.0121, -0.3126,  ...,  0.0598,  0.0273,  0.0182],\n",
              "                      ...,\n",
              "                      [-0.0642, -0.0539, -0.0851,  ...,  0.0272, -0.3821, -0.1290],\n",
              "                      [-0.1862, -0.0718, -0.0711,  ..., -0.0027,  0.1248, -0.1398],\n",
              "                      [-0.3515, -0.0036, -0.2559,  ..., -0.2262, -0.2023, -0.2043]],\n",
              "                     device='cuda:0')),\n",
              "             ('fc2.bias',\n",
              "              tensor([-0.1890, -0.1349, -0.0042, -0.0816,  0.0305, -0.1564, -0.0705, -0.0335,\n",
              "                       0.0685,  0.0230], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(aux)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3leKt2uEpL5H",
        "outputId": "eb215059-05bb-4a2f-f1b3-f6d3fe881e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "5fe3e6f0cdaab8afdc61c52912fda83f7c0a71baaea1897dd7498e2df01e69ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}